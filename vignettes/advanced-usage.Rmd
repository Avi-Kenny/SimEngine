---
title: "Advanced usage"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Advanced usage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(SimEngine)
```

## Complex simulation levels

Often, simulation levels will be simple, such as a vector of sample sizes:

```{r}
sim <- new_sim()
sim %<>% set_levels(
  n = c(200,400,800)
)
```

However, there will be many instances in which more complex objects are needed. For these cases, instead of a vector of numbers or character strings, use a *named* list of lists. The toy example below illustrates this. Note that the list names (`"Beta 1"`, `"Beta 2"`, and `"Normal"`) become the entries in the `sim$results` dataframe.

```{r}
sim <- new_sim()
sim %<>% set_levels(
  n = c(10,100),
  distribution = list(
    "Beta 1" = list(type="Beta", params=c(0.3, 0.7)),
    "Beta 2" = list(type="Beta", params=c(1.5, 0.4)),
    "Normal" = list(type="Normal", params=c(3.0, 0.2))
  )
)
create_data <- function(n, type, params) {
  if (type=="Beta") {
    return(rbeta(n, shape1=params[1], shape2=params[2]))
  } else if (type=="Normal") {
    return(rnorm(n, mean=params[1], sd=params[2]))
  }
}
sim %<>% set_script(function() {
  x <- create_data(L$n, L$distribution$type, L$distribution$params)
  return(list("y"=mean(x)))
})
sim %<>% run()
sim$results
```

## Complex return data

In most situations, the results of simulations will be numeric. However, we may want to return more complex data, such as matrices, lists, or model objects. To do this, we include our complex return data in the list with the special key `".complex"`. This is illustrated in the toy example below, in which we estimate the parameters of a linear regression and returns these as numeric, but also return the estimated covariance matrix and the entire model object.

```{r}
sim <- new_sim()
sim %<>% set_levels(n=c(10, 100, 1000))
create_data <- function(n) {
  x <- runif(n)
  y <- 3 + 2*x + rnorm(n)
  return(data.frame("x"=x, "y"=y))
}
sim %<>% set_config(num_sim=2)
sim %<>% set_script(function() {
  dat <- create_data(L$n)
  model <- lm(y~x, data=dat)
  return (list(
    "beta0_hat" = model$coefficients[[1]],
    "beta1_hat" = model$coefficients[[2]],
    ".complex" = list(
	  "model" = model,
	  "cov_mtx" = vcov(model)
	)
  ))
})
sim %<>% run()
```

After running this simulation, we can examine the numeric results directly by accessing `sim$results` or using the `summarize` function, as usual:

```{r}
sim$results
```

However, we may also want to look at the complex return data. To do so, we use the special function `get_complex`, as illustrated below:

```{r}
c5 <- get_complex(sim, sim_uid=5)
summary(c5$model)
c5$cov_mtx
```

## Using the `batch` function

The `batch` function is useful if you want to share data or objects between simulation replicates. Essentially, it allows you to take your simulation replicates and divide them into "batches"; all replicates in a given batch will then share a single set of objects. The most common use case for this is if you have a simulation that involves generating one dataset, analyzing it using multiple methods, and then repeating this a number of times. To illustrate the use of `batch` using this example, first consider the following simulation:

```{r}
sim <- new_sim()
create_data <- function(n) { rnorm(n=n, mean=3) }
est_mean <- function(dat, type) {
  if (type=="est_mean") { return(mean(dat)) }
  if (type=="est_median") { return(median(dat)) }
}
sim %<>% set_levels(est=c("est_mean","est_median"))
sim %<>% set_config(num_sim=3)
sim %<>% set_script(function() {
  dat <- create_data(n=100)
  mu_hat <- est_mean(dat=dat, type=L$est)
  return(list(
    "mu_hat" = round(mu_hat,2),
    "dat_1" = round(dat[1],2)
  ))
})
sim %<>% run()
```

If we look at the "dat_1" column of the results object (equal to the first element of the `dat` vector created in the simulation script), we see that a unique dataset was created for each simulation replicate:

```{r}
sim$results[order(sim$results$rep_id),]
```

Suppose that instead, we want to run a simulation where we generate one dataset, analyzing it using multiple methods (in this case corresponding to "est_mean" and "est_median"), and then repeating this twice. We can do this using the `batch` function, as follows:

```{r}
sim <- new_sim()
create_data <- function(n) { rnorm(n=n, mean=3) }
est_mean <- function(dat, type) {
  if (type=="est_mean") { return(mean(dat)) }
  if (type=="est_median") { return(median(dat)) }
}
sim %<>% set_levels(est=c("est_mean","est_median"))
sim %<>% set_config(num_sim=3, batch_levels=NULL)
sim %<>% set_script(function() {
  batch({
    dat <- create_data(n=100)
  })
  mu_hat <- est_mean(dat=dat, type=L$est)
  return(list(
    "mu_hat" = round(mu_hat,2),
    "dat_1" = round(dat[1],2)
  ))
})
sim %<>% run()
```

In the code above, we changed two things. One, we added `batch_levels=NULL` to the `set_config` call; don't worry about this for now. Second, we wrapped the code line `dat <- create_data(n=100)` inside the `batch` function. Whatever code goes inside the `batch` function will produce the same output for all simulations in a batch; in this case, if we look at the "dat_1" column of the results object, we can see that one dataset was created and shared by the batch corresponding to sim_uids 1 and 2:

```{r}
sim$results[order(sim$results$rep_id),]
```

However, the situation is often more complicated. What if we have a simulation with multiple level variables, some that correspond to creating data and some that correspond to analyzing the data? This is where the `batch_levels` config option comes in. It is easy to use; simply specify the names of the level variables that are used *within* the batch function. Here is an example:

```{r}
sim <- new_sim()
create_data <- function(n, mu) { rnorm(n=n, mean=mu) }
est_mean <- function(dat, type) {
  if (type=="est_mean") { return(mean(dat)) }
  if (type=="est_median") { return(median(dat)) }
}
sim %<>% set_levels(n=c(10,100), mu=c(3,5), est=c("est_mean","est_median"))
sim %<>% set_config(num_sim=2, batch_levels=c("n", "mu"), return_batch_id=T)
sim %<>% set_script(function() {
  batch({
    dat <- create_data(n=L$n, mu=L$mu)
  })
  mu_hat <- est_mean(dat=dat, type=L$est)
  return(list(
    "mu_hat" = round(mu_hat,2),
    "dat_1" = round(dat[1],2)
  ))
})
sim %<>% run()

sim$results[order(sim$results$batch_id),]
```

We see that we have achieved what we wanted - the batches were created such that each batch contained two replicates, one for each estimator. We also specified the `return_batch_id=T` option in `set_config` so that the results object would return the `batch_id`. The `batch_id` is the variable that defines the batches; all simulations that share the same batch_id. It can be useful to use this option to ensure that you are using the `batch` function correctly.

Here are a few tips to keep in mind when using the batch function:

1. The code within the `batch` code block should *only* create objects; do not attempt to change or delete existing objects, as these changes may be ignored.
2. In the majority of cases, the `batch` function will be called just once, at the top of the simulation script. However, it can be used anywhere in the script and can be called multiple times. Never use `batch` outside of the simulation script.
3. Although we illustrated the use of the `batch` function to create a dataset to share between multiple replicates, it can be used for much more, such as taking a sample from an existing dataset, computing shared nuisance function estimators, performing computationally-intense tasks, and so on.
4. Currently, if your simulation script uses the `batch` function, you cannot update the simulation using the `update_sim` (or `update_sim_on_cluster`), function *unless* all you are doing is removing replicates. This may be changed in the future.

## Setting seeds

In statistical research, it is often desirable to have the ability to reproduce the exact results of a simulation. Since R code often involves stochastic (random) functions like `rnorm` or `sample` that return different values when called multiple times, reproducibility is not guaranteed. In a simple R script, calling the `set.seed` function at the top of your script ensures that the code that follows will produce the same results whenever the script is run. However, a more nuanced strategy is needed when running simulations. If we are running 100 replicates of the same simulation, we typically don't want each replicate to return identical results; rather, we would like for each replicate to be different from one another, but for *the entire set of replicates* to be the same when we run the entire simulation twice in a row. Luckily, **SimEngine** manages this process for you, even when simulations are being run in parallel. **SimEngine** uses a single "global seed" that changes the individual seeds for each simulation replicate; use `set_config` to set or change this global seed:

```{r}
sim %<>% set_config(seed=123)
```

If you did not set a seed with `set_config`, **SimEngine** will set a random seed automatically for you so that you can reproduce the results later if desired. To view this seed, use the `vars` function:

```{r}
sim <- new_sim()
vars(sim, "seed")
```

## Handling errors and warnings

As with any type of programming, debugging is a necessary part of the coding workflow. With simulations, sometimes errors occur that will affect all simulation replicates and sometimes errors occur that only affect some replicates. By default, when a simulation is run, **SimEngine** will not stop if an error occurs; instead, errors are logged and stored in a dataframe along with information about the simulation replicates that resulted in those errors. Examining this dataframe by typing `print(sim$errors)` can sometimes help to quickly pinpoint the issue. This is demonstrated below:

```{r}
sim <- new_sim()
sim %<>% set_config(num_sim=2)
sim %<>% set_levels(
  Sigma = list(
    s1 = list(mtx=matrix(c(3,1,1,2), nrow=2)),
    s3 = list(mtx=matrix(c(4,3,3,9), nrow=2)),
    s2 = list(mtx=matrix(c(1,2,2,1), nrow=2)),
    s4 = list(mtx=matrix(c(8,2,2,6), nrow=2))
  )
)
sim %<>% set_script(function() {
  x <- MASS::mvrnorm(n=1, mu=c(0,0), Sigma=L$Sigma$mtx)
  return(list(x1=x[1], x2=x[2]))
})

sim %<>% run()

sim$errors
```

From the output above, we see that our code fails for the simulation replicates that use the level with `Sigma="s2"` because it uses an invalid covariance matrix. Similarly, if a simulation involves replicates that throw warnings, all warnings are logged and stored in the dataframe `sim$warnings`.

The workflow above can be useful to quickly spot errors, but it has two main drawbacks. First, it can be frustrating to run a time-consuming simulation involving hundreds or thousands of replicates, only to find out at the very end that every replicate failed because of a typo. It is often useful to stop an entire simulation after a single error has occurred. Second, it can sometimes be difficult to determine exactly what caused an error without making use of more advanced debugging tools. For both of these situations, use the following configuration option:

```{r}
sim %<>% set_config(stop_at_error=TRUE)
```

Setting `stop_at_error=TRUE` will stop the simulation when it encounters any error. Furthermore, the error will be thrown by R in the usual way, and so if you are running the simulation in RStudio, you can make use of the built-in debugging tools to find and fix the bug. For example, you can click "Show Traceback" to view the entire call stack and see the function calls that led to the error, or you can click "Rerun with debug" to active the interactive debugger, which reruns the code and pauses execution where the error occurred so that you can examine objects in the function's environment. Try running the code above in RStudio but with the `stop_at_error=TRUE` configuration option, clicking "Rerun with debug", and then typing `print(Sigma)` in the console.
